{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684223c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f715901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp = pd.read_csv('../../Data/play-by-play/pbp_exp12.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d493b180",
   "metadata": {},
   "source": [
    "## Python Feature Importance - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns\n",
    "categorical_cols = [\n",
    "    'OffenseTeam', 'stadium'\n",
    "]\n",
    "\n",
    "# Dictionary to hold LabelEncoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply LabelEncoder to each categorical column and store encoders\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    pbp[col] = le.fit_transform(pbp[col].astype(str))  # Ensure the column is treated as a string\n",
    "    label_encoders[col] = le "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a065de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pbp[['defenders_in_box', 'epa', 'game_seconds_remaining', 'yardline_100',\n",
    "       'score_differential', 'OffenseTeam', 'stadium',\n",
    "       'offensive_predictability', 'current_defence_rank',\n",
    "       'home_team_on_offense', ]]\n",
    "\n",
    "\n",
    "y = pbp['Player-Injured-On-Play']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2260aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 53  \n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists for storing metrics and models\n",
    "accuracy_scores, precision_scores, recall_scores = [], [], []\n",
    "false_positive_cases, false_negative_cases = [], []\n",
    "fold_models = {}\n",
    "feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "\n",
    "# --- Cross-Validation Loop ---\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Separate injured and non-injured plays\n",
    "    X_train_pos = X_train[y_train == 1]\n",
    "    X_train_neg = X_train[y_train == 0]\n",
    "    y_train_pos = y_train[y_train == 1]\n",
    "    y_train_neg = y_train[y_train == 0]\n",
    "\n",
    "    X_test_pos = X_test[y_test == 1]\n",
    "    X_test_neg = X_test[y_test == 0]\n",
    "    y_test_pos = y_test[y_test == 1]\n",
    "    y_test_neg = y_test[y_test == 0]\n",
    "\n",
    "    # Resample to ensure balance\n",
    "    X_train_pos_resampled, y_train_pos_resampled = resample(X_train_pos, y_train_pos, replace=True, n_samples=1619, random_state=42)\n",
    "    X_train_neg_resampled, y_train_neg_resampled = resample(X_train_neg, y_train_neg, replace=False, n_samples=1619, random_state=42)\n",
    "\n",
    "    X_test_pos_resampled, y_test_pos_resampled = resample(X_test_pos, y_test_pos, replace=True, n_samples=1619, random_state=42)\n",
    "    X_test_neg_resampled, y_test_neg_resampled = resample(X_test_neg, y_test_neg, replace=False, n_samples=1619, random_state=42)\n",
    "\n",
    "    # Combine resampled data\n",
    "    X_train_resampled = pd.concat([X_train_pos_resampled, X_train_neg_resampled])\n",
    "    y_train_resampled = pd.concat([y_train_pos_resampled, y_train_neg_resampled])\n",
    "\n",
    "    X_test_resampled = pd.concat([X_test_pos_resampled, X_test_neg_resampled])\n",
    "    y_test_resampled = pd.concat([y_test_pos_resampled, y_test_neg_resampled])\n",
    "\n",
    "    # Train Decision Tree\n",
    "    dt_model = DecisionTreeClassifier(random_state=42, max_depth=6)\n",
    "    dt_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predict & Evaluate\n",
    "    y_pred = dt_model.predict(X_test_resampled)\n",
    "    accuracy_scores.append(accuracy_score(y_test_resampled, y_pred))\n",
    "    precision_scores.append(precision_score(y_test_resampled, y_pred))\n",
    "    recall_scores.append(recall_score(y_test_resampled, y_pred))\n",
    "\n",
    "    # Identify misclassified cases\n",
    "    test_df = X_test_resampled.copy()\n",
    "    test_df['Predicted'] = y_pred\n",
    "    test_df['Actual'] = y_test_resampled\n",
    "    test_df['Fold'] = fold\n",
    "\n",
    "    # Store the trained model\n",
    "    fold_models[fold] = [dt_model, test_df]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dfbc1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.5670\n",
      "Mean Precision: 0.5525\n",
      "Mean Recall: 0.6787\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "#print(f\"Min Accuracy: {min(accuracy_scores):.4f}\")\n",
    "#print(f\"Max Accuracy: {max(accuracy_scores):.4f}\")\n",
    "\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "#print(f\"Min Precision: {min(precision_scores):.4f}\")\n",
    "#print(f\"Max Precision: {max(precision_scores):.4f}\")\n",
    "\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "print(f\"Mean Recall: {mean_recall:.4f}\")\n",
    "#print(f\"Min Recall: {min(recall_scores):.4f}\")\n",
    "#print(f\"Max Recall: {max(recall_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5ff30",
   "metadata": {},
   "source": [
    "## Our Feature Importance - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns\n",
    "categorical_cols = [\n",
    "    'stadium', 'surface_type', 'offense_formation'\n",
    "]\n",
    "\n",
    "# Dictionary to hold LabelEncoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply LabelEncoder to each categorical column and store encoders\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    pbp[col] = le.fit_transform(pbp[col].astype(str))  # Ensure the column is treated as a string\n",
    "    label_encoders[col] = le "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d988466",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pbp[[ 'yardline_100', 'stadium', 'game_seconds_remaining', \n",
    "            'surface_type', 'HOME_day_since_last_game', 'home_team_on_defense', \n",
    "               'defenders_in_box', 'offense_formation','run_count', 'epa']]\n",
    "\n",
    "\n",
    "y = pbp['Player-Injured-On-Play']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6054c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 53  \n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists for storing metrics and models\n",
    "accuracy_scores, precision_scores, recall_scores = [], [], []\n",
    "false_positive_cases, false_negative_cases = [], []\n",
    "fold_models = {}\n",
    "\n",
    "\n",
    "# --- Cross-Validation Loop ---\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Separate injured and non-injured plays\n",
    "    X_train_pos = X_train[y_train == 1]\n",
    "    X_train_neg = X_train[y_train == 0]\n",
    "    y_train_pos = y_train[y_train == 1]\n",
    "    y_train_neg = y_train[y_train == 0]\n",
    "\n",
    "    X_test_pos = X_test[y_test == 1]\n",
    "    X_test_neg = X_test[y_test == 0]\n",
    "    y_test_pos = y_test[y_test == 1]\n",
    "    y_test_neg = y_test[y_test == 0]\n",
    "\n",
    "    # Resample to ensure balance\n",
    "    X_train_pos_resampled, y_train_pos_resampled = resample(X_train_pos, y_train_pos, replace=True, n_samples=1619, random_state=42)\n",
    "    X_train_neg_resampled, y_train_neg_resampled = resample(X_train_neg, y_train_neg, replace=False, n_samples=1619, random_state=42)\n",
    "\n",
    "    X_test_pos_resampled, y_test_pos_resampled = resample(X_test_pos, y_test_pos, replace=True, n_samples=1619, random_state=42)\n",
    "    X_test_neg_resampled, y_test_neg_resampled = resample(X_test_neg, y_test_neg, replace=False, n_samples=1619, random_state=42)\n",
    "\n",
    "    # Combine resampled data\n",
    "    X_train_resampled = pd.concat([X_train_pos_resampled, X_train_neg_resampled])\n",
    "    y_train_resampled = pd.concat([y_train_pos_resampled, y_train_neg_resampled])\n",
    "\n",
    "    X_test_resampled = pd.concat([X_test_pos_resampled, X_test_neg_resampled])\n",
    "    y_test_resampled = pd.concat([y_test_pos_resampled, y_test_neg_resampled])\n",
    "\n",
    "    # Train Decision Tree\n",
    "    dt_model = DecisionTreeClassifier(random_state=42, max_depth=6)\n",
    "    dt_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predict & Evaluate\n",
    "    y_pred = dt_model.predict(X_test_resampled)\n",
    "    accuracy_scores.append(accuracy_score(y_test_resampled, y_pred))\n",
    "    precision_scores.append(precision_score(y_test_resampled, y_pred))\n",
    "    recall_scores.append(recall_score(y_test_resampled, y_pred))\n",
    "\n",
    "    # Identify misclassified cases\n",
    "    test_df = X_test_resampled.copy()\n",
    "    test_df['Predicted'] = y_pred\n",
    "    test_df['Actual'] = y_test_resampled\n",
    "    test_df['Fold'] = fold\n",
    "\n",
    "    # Store the trained model\n",
    "    fold_models[fold] = [dt_model, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c15ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.5745\n",
      "Mean Precision: 0.5582\n",
      "Mean Recall: 0.6954\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "#print(f\"Min Accuracy: {min(accuracy_scores):.4f}\")\n",
    "#print(f\"Max Accuracy: {max(accuracy_scores):.4f}\")\n",
    "\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "#print(f\"Min Precision: {min(precision_scores):.4f}\")\n",
    "#print(f\"Max Precision: {max(precision_scores):.4f}\")\n",
    "\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "print(f\"Mean Recall: {mean_recall:.4f}\")\n",
    "#print(f\"Min Recall: {min(recall_scores):.4f}\")\n",
    "#print(f\"Max Recall: {max(recall_scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
